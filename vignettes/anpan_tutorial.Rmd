---
title: "anpan tutorial"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    code_folding: show
bibliography: anpan_vignette_refs.bib
vignette: >
  %\VignetteIndexEntry{anpan_tutorial}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 8px;
}
h1.title {
  font-size: 38px;
}
h1 { /* Header 1 */
  font-size: 28px;
}
h2 { /* Header 2 */
    font-size: 22px;
}
h3 { /* Header 3 */
  font-size: 18px;
}
</style>

<!-- https://stackoverflow.com/questions/30446905/rmarkdown-font-size-and-header -->

# Introduction

It's difficult to find associations between microbial strains and host health outcomes due to their fine resolution and non-recurrence across individuals. This package, anpan, aims to make inferring those relationships a bit easier by providing an interface to our strain analysis functionality. This functionality covers three main points:

* Adaptive sample filtering of per-bug microbial gene profiles to identify and discard samples in which the bug is not present
* Modeling the association between outcome variables and microbial gene presence while accounting for covariates
* Modeling the association between outcome variables and the phylogeny of strains within a given microbial species
* Modeling the difference in microbial pathways between experimental groups while controlling for species abundance.

We'll cover each of these points in a top-level section. Currently the only section fleshed out in this tutorial is the [PGLMMs] section.

# Libraries

If you need installation instructions, please see [the readme on Github](https://github.com/biobakery/anpan#dependencies). 

We'll start by loading the library in this code chunk:

```{r}
library(anpan)
```

The startup message points out that you can easily parallelize / show progress bars for most long-running computations in `anpan` by setting `plan()` and `handlers()` after loading the `furrr` and `progressr` packages. For most users `plan(multisession, workers = 4)` and `handlers(global = TRUE)` are probably close to what you want, though both the [parallelization strategy](https://future.futureverse.org/reference/plan.html) and [progress reporting](https://progressr.futureverse.org/articles/progressr-intro.html#customizing-how-progress-is-reported) are highly customizable.

A couple points to know about anpan function names:

* All of the modeling functions in anpan are prefixed with `anpan_`, so if you type that into the RStudio console the auto-complete prompt should show a list of all the modeling functions. This can help you find the function you need quickly without having to dig through the documentation. 
  * Several functions have a `_batch()` version, which applies a given model to each bug present in a user-specified input directory.
* Same goes for the plotting functions and the `plot_` prefix. 

This code chunk loads some other packages we'll use:

```{r message = FALSE, warning=FALSE, class.source = "fold-show"}
library(data.table)
library(ggplot2)
library(tibble)
library(dplyr)
library(ape)
```

# PGLMMs

Phylogenetic generalized linear mixed models (PGLMMs) are probabilistic models that account for phylogenetic structure. For a PGLMM with a simple linear regression as the base model, the model structure is as follows:

$$ y = X \beta + (1|\text{leaf}) + \epsilon $$
            
$$(1|\text{leaf}) \sim \text{MVNormal}(0, σ_p^2\Omega)$$

$$\epsilon \sim \text{Normal}(0, σ_R^2)$$

The outcome $y$ is modeled as a function of some familiar terms: covariates $X$, coefficients $\beta$, and residual noise $\epsilon$. The key addition is the phylogenetic term $(1|\text{leaf})$, which contains a "random effect" for each observation in $y$. Unlike typical random effects (which are usually independent between different levels of the random effect variable), the values in the phylogenetic term follow a pre-specified correlation structure $\Omega$, which is derived from a tree. The variability of the phylogenetic term is scaled by the "phylogenetic noise" parameter $\sigma_{phylo}$.

To understand how a tree implies a correlation structure, consider the plot below showing a phylogenetic tree and the lower triangle of the correlation matrix it implies. You can see that the clade on the left (with low inter-leaf distances between its members) forms a bright sub-block of high correlation in the matrix. The tiny clade on the far right has high inter-leaf distance between its members and the rest of the tree, so its members generally have low correlation with the rest of the leaves, exhibited by the dark band on the right of the triangle. Note that the matrix is derived solely from the structure of the tree -- it is not influenced by the colored outcome dots. The correlation matrix numerically quantifies the "higher inter-leaf distance → lower correlation" principle.

```{r echo=FALSE}
knitr::include_graphics("vignette_figs/tree_hcm.png")
```

We can see in the synthetic example above that the tree clearly does impact the outcome: the two well-separated clades clearly show very different outcome values. A PGLMM evaluated on this data would easily detect such a blazing signal, so in the next section we'll simulate a tree with an outcome that's realistically noisier and less visually obvious.

## Simulate data

To demonstrate the PGLMM functionality, we'll simulate a tree, a single covariate `x`, and an outcome variable `y`. We'll use `n = 100`, `sigma_phylo = 1` and `sigma_resid = 1`. 

The code chunk below sets a randomization seed and the parameters we'll use, then generates a random tree:

```{r eval = TRUE}
set.seed(123)

n = 120
sigma_phylo = 1
sigma_resid = 1

tr = ape::rtree(n)
```

You can try `plot(tr)` if you want to take a quick look at your tree, but we'll examine it with some additional detail later.

The chunk below derives the correlation matrix implied by the tree:
```{r}
cor_mat = ape::vcv.phylo(tr, corr = TRUE)

cor_mat[1:5,1:5]
```

The "t#" labels are the default sample IDs that `ape::rtree()` puts as tip labels.


The chunk below generates a normally distributed covariate `covariate`, the linear term contribution, the true phylogenetic effects we'll use, and the outcome variable `outcome`, all stored in a tibble called `metadata`. Note that the effect size of the linear covariate is explicitly set to 1:
```{r}
covariate = rnorm(n)

linear_term = rnorm(n, mean = 1 * covariate, sd = sigma_resid)

true_phylo_effects = sigma_phylo * MASS::mvrnorm(1, mu = rep(0, n), Sigma = cor_mat)

metadata = tibble(sample_id = colnames(cor_mat),
                  covariate = covariate,
                  outcome   = linear_term + true_phylo_effects)

metadata
```

Now we have our tree and the metadata that goes along with it. A quick plot shows that the outcome correlates with the simulated covariate as desired:

```{r class.source = "fold-hide"}
ggplot(metadata, aes(covariate, outcome)) + 
  geom_point() + 
  labs(title = "The simulated covariate correlates with the outcome") + 
  theme_light()
```

We can use the function `anpan::plot_outcome_tree()` to visually inspect the tree and confirm that it also appears related to the outcome. The dot on each leaf is shaded according to the outcome:

```{r fig.retina=3, out.width="120%"}
plot_outcome_tree(tr,
                  metadata, 
                  covariates = NULL,
                  outcome    = "outcome")
```

You can sort of see by eye that the phylogeny correlates with the outcome. The middle clade is generally brighter, and close neighbors usually have about the same shade of color.

How do we *quantitatively* assess the impact of the phylogeny on the outcome while also building in the relationship with the covariate? Use a PGLMM.

## Fit the PGLMM

The code chunk below shows how to use `anpan` to fit a PGLMM that examines this data for phylogenetic patterns while adjusting for our covariate. It will take a couple minutes to run. By default `anpan_pglmm` regularizes the noise ratio `sigma_phylo / sigma_resid` with a Gamma(1,2) prior and runs a leave-one-out model comparison against a "base" model that doesn't have the phylogenetic component. The default `family = "gaussian"` argument means the residual error is normally distributed. This can be changed to `family = "binomial"` with a binary outcome to run a phylogenetic logistic regression. 

```{r eval = TRUE, message=FALSE, results = "hide", warning=FALSE, out.width = "120%"}
result = anpan_pglmm(meta_file      = metadata,
                     tree_file      = tr,
                     outcome        = "outcome",
                     covariates     = "covariate",
                     family         = "gaussian",
                     bug_name       = "sim_bug",
                     reg_noise      = TRUE,
                     loo_comparison = TRUE,
                     refresh        = 500,
                     show_plot_tree = FALSE,
                     show_post      = FALSE)
```

Aside from fitting the model, this command prints a plot (and a lot of console output with messages about the progression of the MCMC sampler). This plots shows the correlation matrix implied by the tree. This is how the PGLMM sees the correlation structure of the leaves. (Side note: the randomized tree name shows up because we didn’t provide one explicitly and the function wasn’t able to pull one from the tree input either).

If you want to tl;dr the rest of the PGLMMs section, look at the model comparison result to decide if the phylogeny is informative beyond the base model: 

```{r}
result$loo$comparison
```

The PGLMM is the best fitting model, and the difference in ELPD (i.e. predictive performance score) for the base model is more than two standard errors below zero. So in this case you can say the phylogeny clearly contributes to the outcome. Given that we simulated the tree with $\sigma_{phylo} > 0$, that is the correct conclusion.

If you want to see how the fit sees the effect of the tree, you can examine the posterior distribution on the phylogenetic with a simple interval plot laid out below the tree using `plot_tree_with_post()` (or leave `show_post` at its default `TRUE` value in the above call to `anpan_pglmm()`):

```{r out.width='120%'}
plot_tree_with_post(tr,
                    metadata,
                    fit        = result$pglmm_fit,
                    covariates = "covariate",
                    outcome    = "outcome",
                    labels     = metadata$sample_id)
```

You can see that the model fit confirms what we observed visually earlier: the phylogenetic effect generally shifts the outcome up in the middle clade and tightly correlated neighbors generally have very similar phylogenetic effects.

But how do we estimate *clade* effects? It's important to contextualize the results in terms of the model formulation. A PGLMM doesn't see the tree, it sees the correlation matrix $\Omega$. Human eyes can easily pick out blocks in the matrix as discrete clades, but the model sees only a single, constrained multivariate distribution. So a presentation like this where the phylogenetic effects are set against the tree is a simple presentation of the raw model fit, but can't draw the sharp dividing lines we might want. 

If you are able to justifiably define a clade (with some articulable reason beyond "this clade looks like it has a higher outcome") manually, you can use the function `compute_clade_effects()` to compare the average phylogenetic effect of clade members against that of non-members. However automating the selection of clades is non-trivial and beyond the scope of this package, so we won't be demonstrating that function here.

## Detailed interpretation

`result` is a list with five elements:

* `model_input` - the input metadata that made it into the analysis after taking the samples that overlapped with the leaves of the tree, re-ordered to the order of samples given in the correlation matrix.
* `cor_mat` - the correlation matrix derived from the tree
* `pglmm_fit` - a [CmdStanMCMC](https://mc-stan.org/cmdstanr/reference/CmdStanMCMC.html) object containing the PGLMM fit
* `base_fit` - another [CmdStanMCMC](https://mc-stan.org/cmdstanr/reference/CmdStanMCMC.html) object containing the "base" GLM fit (without the phylogenetic component)
* `loo` - a list containing four elements: 
    * `pglmm_loo` - a [loo()](https://mc-stan.org/loo/) result for the PGLMM model using integrated importance weights
    * `pglmm_ll_mat` - a matrix giving the integrated log-likelihood importance weights with for posterior iterations (rows) of each leaf (columns)
    * `base_loo` - a [loo()](https://mc-stan.org/loo/) result for the base model
    * `comparison` - a [loo_compare()](https://mc-stan.org/loo/reference/loo_compare.html) result comparing the two models by leave-one-out predictive performance.
    
The  `pglmm_fit` part of the result is the model fit produced by `cmdstanr` for the PGLMM. Any method applicable to [CmdStanMCMC objects](https://mc-stan.org/cmdstanr/reference/CmdStanMCMC.html) works on this, but of particular interest is the `summary()` method which we'll use to inspect model fit.

### Inspect model fit

We'll use the `summary()` method here to pull out the posterior means for several parameters (black) and compare them to their true values (red). These parameters include for the covariate effects `beta`, the `intercept`, residual noise term `sigma_resid`, the spread of phylogenetic effects `sigma_phylo` and the per-leaf phylogenetic effects (which are indexed in the same order as `model_input`):

```{r out.width = "120%"}
post_summary = result$pglmm_fit$summary() |> 
  filter(grepl("beta|^intercept|sigma|^phylo_effect", variable)) |> 
  mutate(true_value = c(1,1,1, true_phylo_effects, 0))

post_summary[-c(4:113),] |> 
  ggplot(aes(mean, variable)) + 
  geom_point() + 
  geom_segment(aes(x = q5, xend = q95,
                   y = variable, yend = variable)) + 
  geom_point(aes(x = true_value), 
             color = 'firebrick1',
             size = 3) + 
  labs(x = 'value',
       y = 'parameter',
       title = 'Posterior mean & 90% interval in black, true values in red') + 
  theme_light()
```

Most of the phylogenetic effects are cut from the plot for the sake of visibility. We can see that the posterior mean for beta[1] (the effect of the covariate) is fairly close to the true value (1), as are the intercept (0) and noise terms (1 and 1). Importantly, the 90% posterior intervals capture the true values.

So we mostly recaptured our simulation parameters, but how well does the model really fit the data overall? We can use `anpan::plot_tree_with_post_pred()` to overlay the posterior predictive distribution for each leaf and show that, if held out, our model's predictions for that point would usually capture the true observation:

```{r out.width = "120%"}
anpan::plot_tree_with_post_pred(tree_file  = tr,
                                meta_file  = metadata,
                                covariates = "covariate",
                                outcome    = "outcome",
                                fit        = result$pglmm_fit,
                                labels     = metadata$sample_id,
                                verbose    = FALSE)
```
So when observations (the colored dots) are held out, the posterior predictive distribution for each leaf (the boxplots) generally capture the true value, showing that our model generally fits the data well.

What about the posterior on the linear model component? We can visualize that by taking some of the posterior draws (with `cmdstanr::draws()`) of the line (the parameters `beta[1]` and `intercept`) and overlay those onto the `outcome ~ covariate` scatterplot:

```{r}
line_draws = result$pglmm_fit$draws(format = 'data.frame') |> 
  as_tibble() |> 
  select(beta = `beta[1]`, intercept) |> 
  slice_sample(n = 40)

result$model_input |> 
  ggplot(aes(covariate, outcome)) + 
  geom_point() + 
  geom_abline(data = line_draws,
              aes(slope = beta,
                  intercept = intercept),
              alpha = .2) + 
  theme_light()

```

You can see that there's a bit more uncertainty in the slope and intercept than you might expect. This is because the model has to assess this relationship in the context of the very flexible phylogenetic component. If $\sigma_{phylo}$ is high and the phylogenetic component if explaining most of the residual variation here, the linear component is free to relax toward the prior distribution. Vice versa if the phylogenetic component explains the variation poorly.

### `loo` interpretation

Let's look at the `pglmm_loo` result:

```{r}
result$loo$pglmm_loo
```

PGLMM models are very flexible because they have a parameter for every leaf. In some cases, this can cause the naive leave-one-out importance weights calculated from raw log-likelihood values to be unstable. `anpan` generates importance weights for each observation by integrating the conditional likelihood for each observation at each posterior iteration as described in section 3.6.1 of @vehtari_glvm. This produces stable importance weights that we can use for model comparison. Note that unstable importance weights can still occur if the posterior on phylogenetic effects are poorly constrained by the tree (i.e. the correlation matrix is close to the identity matrix) and/or data (i.e. n is low, typically <100 for continuous outcomes or <200 for binary outcomes, though these cutoffs depend heavily on the tree as well).

The `loo()` result provides some diagnostics that can help confirm that the importance weights are stable and we can trust the downstream model comparison. In this case, we get a small number of Pareto k diagnostic values that are only "okay". If there are bad or "very bad" k values, that indicates that individual observations are having a strong effects on the model fit, and hence that the loo-based model comparison shouldn't be trusted. That scenario can happen more frequently without regularization when `reg_noise = FALSE`. 

We only got a small number of non-good Pareto k value here (and none that were bad), so in this case the model comparison should be fine.

Let's look at the model comparison:

```{r}
result$loo$comparison
```

The `loo` package prints model comparison objects by placing the model with the best leave-one-out predictive performance on the first row, in this case the PGLMM fit. The difference in expected log pointwise predictive density (ELPD) compared to the other model is shown in the first column along with a standard error of the difference in the second column. Here the ELPD difference is about `r round(result$loo$comparison[2,1], digits = 1)` with a SE around +/- `r round(result$loo$comparison[2,2], digits = 1)`, which is both large and clearly non-zero. So here we would conclude that the phylogenetic component of the PGLMM clearly fits better than the base linear model. Given that we simulated the tree with $\sigma_{phylo} \neq 0$, that is the correct conclusion.

There's a lot more to be said about loo model comparison that is beyond the scope of this vignette. You can read more interpretation of loo results on the [Cross-validation FAQ](https://avehtari.github.io/modelselection/CV-FAQ.html#11_What_is_the_interpretation_of_ELPD__elpd_loo__elpd_diff) written by the loo authors. 

# Element testing

## Get example data

In this section we'll simulate a small dataset for a single bug. If you have your own data or would like to use the example data built into the package, you can skip this section and go straight to [Apply `anpan`]. You can get the paths to the data included with the package with these two commands:

```{r eval = TRUE}
meta_path = system.file("extdata", "fake_metadata.tsv", 
                        package = "anpan", mustWork = TRUE)
bug_path = system.file("extdata", "g__Madeuppy.s__Madeuppy_Fakerii.genefamilies.tsv.gz", 
                       package = "anpan", mustWork = TRUE)
```

### Simulate example data

This section simulates some data for 200 samples in a synthetic bug with 500 genes. The simulation doesn't look realistically noisy (see the plots in the README / manuscript for that), but it incorporates the generative features anpan aims to pick up on.

First we set some of the simulation parameters and a random seed:

```{r eval = FALSE}
n_per_group = 100
n_gene = 500

out_dir = tempdir()

set.seed(123)
```

Then we generate the simulated metadata. The `has_bug` column is an indicator if a given sample has the bug at all. Roughly a quarter of our samples don't.

```{r eval = FALSE}
sim_meta = data.table(sample_id = paste0('sample_', 1:(2 * n_per_group)),
                      is_case   = rep(c(FALSE, TRUE), 
                                      each = n_per_group),
                      has_bug   = sample(x       = c(TRUE, FALSE),
                                         prob    = c(.75, .25), 
                                         size    = 2 * n_per_group,
                                         replace = TRUE))

meta_path = file.path(out_dir, "fake_metadata.tsv")

fwrite(sim_meta,
       file = meta_path)
```

We simulate the gene-level data in the blocks below. A couple notes on what's going on here:

* we set the first five genes to have a non-zero true effect
* the bug and gene abundances are modeled on the log scale 
* the log abundances (`labd`) come from a skew normal distribution, which we define in the function `rskewnormal` (adapted from the [`sn` package](https://cran.r-project.org/web/packages/sn/index.html))
* gene log-abundances below the 33rd percentile are truncated to -Inf i.e. are zeroed out.

First we create the simulated metadata: 
```{r eval = FALSE}
true_effects = data.table(gene   = paste0("UniRef90_ABC", 1:(n_gene)),
                          effect = c(rnorm(5, sd = 2), 
                                     rep(0, (n_gene - 5))))

sim_grid = sim_dat = expand.grid(gene      = paste0("UniRef90_ABC", 1:(n_gene)),
                                 sample_id = paste0('sample_', 1:(2*n))) |>
  as.data.table()
```

Then we simulate the log-abundances. If a sample doesn't have a bug present, it drops the bug abundance. Gene log-abundance is proportional to bug abundance and in cases, the true effect of the gene (which really flips the causal direction of `anpan()`, but for a simulation this simple it doesn't matter).

```{r eval = FALSE}
rskewnormal = function(n, location = 0, scale = 1, skew = 0) {
  # adapted from sn::rsn()
  
  delta = skew / sqrt(1 + skew^2)
  chi   = abs(rnorm(n))
  nrv   = rnorm(n)
  
  z = delta * chi + sqrt(1 - delta^2) * nrv

  return(location + scale * z)
}

sim_meta[, bug_labd := rskewnormal(n        = nrow(sim_meta),
                                   location = -2,
                                   skew     = -3) +
                       -2.5 * (!has_bug)]

sim_df = sim_grid[sim_meta, on = 'sample_id'][true_effects, on = 'gene']

sim_df[, gene_labd := rskewnormal(n        = nrow(sim_df),
                                  location = -1 + .5*bug_labd + is_case * effect,
                                  skew     = -3,
                                  scale    = 3)]

sim_df$gene_labd[sim_df$gene_labd < quantile(sim_df$gene_labd,
                                             probs = .333)] = -Inf
```

The block below performs a bit of formatting to make the simulated data look like real [HUMAnN](https://huttenhower.sph.harvard.edu/humann) data. It :

* exponentiates the log-abundances
* pivots to wide format
* adds on the fake species identifier to the gene column
* and renames to the gene column to `# Gene Family`

```{r eval = FALSE}
sim_df[, gene_abd := exp(gene_labd)]

sim_wide = dcast(sim_df[, .(gene, sample_id, gene_abd)],
                 gene ~ sample_id,
                 value.var = "gene_abd")

sim_wide[, gene := paste0(gene, "|g__Madeuppy.s__Madeuppy_Fakerii")]

names(sim_wide)[1] = "# Gene Family"
```

Then we write out the simulated data. The name of the file isn't important, but here we've chosen to follow the naming conventions of [HUMAnN](https://huttenhower.sph.harvard.edu/humann).

```{r eval = FALSE}
bug_path = file.path(out_dir, "g__Madeuppy.s__Madeuppy_Fakerii.genefamilies.tsv.gz")

fwrite(sim_wide,
       file = bug_path)
```

## Apply `anpan`

Now that we have `bug_path` and `meta_path` set, we can run the filtering and modeling with `anpan()`. If you have multiple bug files in a single directory, use `anpan_batch()` instead and set the `bug_dir` argument instead of `bug_file`. 

The code block below shows the `anpan()` function call. The outcome argument is set to `is_case` the logical indicator of case status. Note that this means anpan will be running logistic regression models for each gene. In this case, we have no covariates to include, so we set that argument to `NULL`. The output directory is set to a sub-directory of the tempdir() we've been using so far, but it could be somewhere more permanent if you like.  

```{r}
anpan_res = anpan(bug_file = bug_path,
                  meta_file = meta_path,
                  out_dir = file.path(tempdir(), "anpan_output"),
                  covariates = NULL,
                  outcome = "is_case",
                  model_type = "fastglm",
                  discretize_inputs = TRUE)

head(anpan_res)
```

You can see from the first set of messages that it seems to have identified most of the ~50 samples that didn't have the bug present in the simulation.

`anpan()` returns a tibble with regression statistics for the effect of each gene on the outcome. We can see that the two top-ranked hits (and the only two that pass a Q < .01 threshold) are the strongest genes from the list of true effects. We don't get the second through fourth genes with (weaker) true effects, meaning we likely didn't have enough power in this simulation to detect those. 

## Examine filtering diagnostics

Before interpreting the model results, it's important to ensure that the filtering step didn't go awry. `anpan()` calls the function `read_and_filter()` internally, which applies

* an initial prevalence filter to genes 
* a sample filter to remove samples where the species in question is absent
* and then a final prevalence filter to remove any marginal genes that don't pass the prevalence filter 

The outputs of the filtering step goes into the `filter_stats/` directory inside the specified `out_dir`. The final filtered data (which is the input to the modeling step) is in `filter_stats/filtered_*.tsv.gz` where * represents the bug name. The `filter_stats/labels/` directory contains the calls of which samples contained the bug. The `filter_stats/plots/` directory contains diagnostic plots from the filtering step.

```{r eval = FALSE, echo = FALSE}
knitr::include_graphics() #show lines and kmeans plots
```


## Examine gene model results

We can visulize the results with `plot_results()` as in the code block below. This function is called automatically on each bug when using `anpan_batch(). 

```{r eval = FALSE}
plot_results()
```


# Pathway random effects model

This section isn't done.

```{r eval = FALSE}
?anpan_pwy_ranef_batch()
```


# References

<div id="refs"></div>

# Session Info

```{r}
sessionInfo()
```


